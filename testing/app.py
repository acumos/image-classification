#!/usr/bin/env python3
import connexion
import logging

import argparse
import json
import time

from flask import Flask, request, current_app, make_response

import pandas as pd
import requests

from cognita_client.wrap.load import load_model
from image_classifier.keras.prediction_formatter import Formatter


#def invoke_method(model_method):
def transform(mime_type, image_binary, rich_output=False):
    app = current_app
    time_start = time.clock()
    image_read = image_binary.stream.read()
    X = pd.DataFrame([['image/jpeg', image_read]], columns=['mime_type', 'binary_stream'])

    pred = app.model.transform.from_native(X).as_native()
    time_stop = time.clock()

    if rich_output:
        # NOTE: This response is specially formatted for the webdemo included with this package.
        #       Alternate forms of a response are viable for any other desired application.
        retObj = {
            'classes': [],
            'clientfile': 'undefined',
            'info': 'Processed',
            'processingtime': (time_stop - time_start),
            'serverfilename': '/dev/null',
            'status': 'Succeeded'
        }

        # iterate through predictions
        for r in zip(pred[Formatter.COL_NAME_CLASS], pred[Formatter.COL_NAME_PREDICTION], range(len(pred))):
            retObj['classes'].append({'class':r[0], 'rank':r[2], 'score':r[1], 'idx':0 })

        # dump to pretty JSON
        retStr = json.dumps({'results':retObj}, indent=4)
    else:
        retStr = json.dumps(pred.to_dict(orient='records'), indent=4)

    # formulate response
    resp = make_response((retStr, 200, { } ))
    # allow 'localhost' from 'file' or other;
    # NOTE: DO NOT USE IN PRODUCTION!!!
    resp.headers['Access-Control-Allow-Origin'] = '*'
    print(type(pred))
    print(retStr[:min(200,len(retStr))])
    #print(pred)
    return resp


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument("--port", type=int, default=8885, help='port to launch the simple web server')
    parser.add_argument("--modeldir", type=str, default='../model', help='model directory to load dumped artifact')
    pargs = parser.parse_args()

    print("Configuring local application... {:}".format(__name__))
    logging.basicConfig(level=logging.INFO)
    app = connexion.App(__name__)
    app.add_api('swagger.yaml')
    # example usage:
    #     curl -F image_binary=@test.jpg -F mime_type="image/jpeg" "http://localhost:8885/transform"

    print("Loading model... {:}".format(pargs.modeldir))
    app.app.model = load_model(pargs.modeldir)  # refers to ./model dir in pwd. generated by helper script also in this dir
    # # dynamically add handlers depending on model capabilities
    # for method_name, method in model.methods.items():
    #     url = "/{}".format(method_name)
    #     print("Adding route {}".format(url))
    #     handler = partial(invoke_method, model_method=method)
    #     app.add_url_rule(url, method_name, handler, methods=['POST'])

    # run our standalone gevent server
    app.run(port=pargs.port) #, server='gevent')
